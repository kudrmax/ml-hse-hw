- [Задание 1. Датасет 1](#дз-1-первый-датасет)
- [Задание 1. Датасет 2](#дз-1-второй-датасет)
- [Задание 2](#задание-2)

# Задание 1

[Открыть задание](TASK.md)

Сделал одно и тоже над двумя датасетами, потому что было интересно попробовать разные данные.

### ДЗ-1. Первый датасет

- Датасет: [Car Classification Dataset](https://www.kaggle.com/datasets/stealthtechnologies/car-evaluation-classification)
- [Открыть ноутбук с решением](solution1.ipynb)

#### Вывод

В даннной задаче логистическая регрессия показала себя лучше, чем дерево решений. ROC-AUC для логистической регрессии составил 0.975, что достаточно высокий результат.

Метрики для лог. реграсии:
- precision=0.95
- recall=0.78
- f1-score=0.86

Это значит, что модель достаточно хорошо выявляет спам (precision) и выявила 78% всех true positive

### ДЗ-1. Второй датасет

- Датасет: Spam Email classification (источник утерян, датасет был дан на каком-то старом тестовом задании)
- [Открыть ноутбук с решением](solution2.ipynb)

#### Вывод

В даннной задаче логистическая регрессия показала себя значительно хуже, чем дерево решений. ROC-AUC для дерева решений
составил 0.9820, а для лог. регрессии всего 0.77

Для дерева решений f1 скор = 0.98, что показывает на хороший баланс между precision и recall (как и сами этим 2 метрики
хорошие). На смаом деле похоже на то, что модель переобучилась (насколько я знаю дерево решений имеет к этому
склонность).


# Задание 2

### ДЗ-2. 

- Датасет: [Default of Credit Card Clients Data Set](https://code.datasciencedojo.com/datasciencedojo/datasets/tree/master/Default%20of%20Credit%20Card%20Clients)
- [Открыть ноутбук с решением](solution2.ipynb)

#### Вывод

Все 3 модели показали достаточно низкие результаты. Лучше всех себя показал градиентный бустинг с ROC-AUC 0.77.

Масштабирование признаков не дало особого прироста — увеличился ROC-AUC для лог. регресси и уменьшился для дерева решений. Показатель градиентного бустинга почти не изменился

В датасете были немного кривые данные — признаки, которые означают количество были иногда отрицательными.

Как бы я не пытался улучшить итоговые показатели — 0.77 у градиентного бустинга — лучший результат.
